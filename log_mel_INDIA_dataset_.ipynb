{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f2f614b",
      "metadata": {
        "id": "9f2f614b"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "from numpy import *\n",
        "\n",
        "from PIL import Image\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "503cf373",
      "metadata": {
        "id": "503cf373"
      },
      "outputs": [],
      "source": [
        "#stroring imagename, language, file path, language code\n",
        "#here we use language code for tamil is 1, telugu is 0, urdu is 2\n",
        "import pandas as pd\n",
        "col=['filename','language','file_path','lan_code'] #creating dataframe\n",
        "df=pd.DataFrame(columns=col)\n",
        "p=os.listdir(r\"C:\\Users\\91957\\Desktop\\final_project\\process\\train\") #chaning directory lo location where we save spectrogram images\n",
        "for i in p:\n",
        "    l=i.split(\"_\")\n",
        "    f=i\n",
        "    la=l[0]\n",
        "    fp=r\"C:\\Users\\91957\\Desktop\\final_project\\process\\train\"+\"/\"+i\n",
        "    if l[0]==\"tamil\":\n",
        "        lc='0'\n",
        "    elif l[0]==\"telugu\":\n",
        "        lc='1'\n",
        "    elif l[0]==\"urdu\":\n",
        "        lc='2'\n",
        "\n",
        "    df.loc[len(df.index)]=[i,la,fp,lc]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0839c4a",
      "metadata": {
        "id": "a0839c4a"
      },
      "outputs": [],
      "source": [
        "#spliting dataframe into train and test\n",
        "train=df.sample(frac=0.8,random_state=200) #random state is a seed value\n",
        "test=df.drop(train.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddcbdef",
      "metadata": {
        "id": "9ddcbdef",
        "outputId": "060a6559-6782-4b1c-bcf3-e00ea5dc105b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>language</th>\n",
              "      <th>gender</th>\n",
              "      <th>file_path</th>\n",
              "      <th>lan_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tamil_1_1.wav.png</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tamil_1_11.wav.png</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tamil_1_15.wav.png</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>tamil_1_16.wav.png</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>tamil_1_25.wav.png</td>\n",
              "      <td>tamil</td>\n",
              "      <td>1</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>urdu_6_30.wav.png</td>\n",
              "      <td>urdu</td>\n",
              "      <td>6</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>727</th>\n",
              "      <td>urdu_6_34.wav.png</td>\n",
              "      <td>urdu</td>\n",
              "      <td>6</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>734</th>\n",
              "      <td>urdu_6_40.wav.png</td>\n",
              "      <td>urdu</td>\n",
              "      <td>6</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>743</th>\n",
              "      <td>urdu_6_49.wav.png</td>\n",
              "      <td>urdu</td>\n",
              "      <td>6</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746</th>\n",
              "      <td>urdu_6_6.wav.png</td>\n",
              "      <td>urdu</td>\n",
              "      <td>6</td>\n",
              "      <td>C:\\Users\\91957\\Desktop\\final_project\\process\\t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               filename language gender  \\\n",
              "0     tamil_1_1.wav.png    tamil      1   \n",
              "2    tamil_1_11.wav.png    tamil      1   \n",
              "6    tamil_1_15.wav.png    tamil      1   \n",
              "7    tamil_1_16.wav.png    tamil      1   \n",
              "17   tamil_1_25.wav.png    tamil      1   \n",
              "..                  ...      ...    ...   \n",
              "723   urdu_6_30.wav.png     urdu      6   \n",
              "727   urdu_6_34.wav.png     urdu      6   \n",
              "734   urdu_6_40.wav.png     urdu      6   \n",
              "743   urdu_6_49.wav.png     urdu      6   \n",
              "746    urdu_6_6.wav.png     urdu      6   \n",
              "\n",
              "                                             file_path lan_code  \n",
              "0    C:\\Users\\91957\\Desktop\\final_project\\process\\t...        0  \n",
              "2    C:\\Users\\91957\\Desktop\\final_project\\process\\t...        0  \n",
              "6    C:\\Users\\91957\\Desktop\\final_project\\process\\t...        0  \n",
              "7    C:\\Users\\91957\\Desktop\\final_project\\process\\t...        0  \n",
              "17   C:\\Users\\91957\\Desktop\\final_project\\process\\t...        0  \n",
              "..                                                 ...      ...  \n",
              "723  C:\\Users\\91957\\Desktop\\final_project\\process\\t...        2  \n",
              "727  C:\\Users\\91957\\Desktop\\final_project\\process\\t...        2  \n",
              "734  C:\\Users\\91957\\Desktop\\final_project\\process\\t...        2  \n",
              "743  C:\\Users\\91957\\Desktop\\final_project\\process\\t...        2  \n",
              "746  C:\\Users\\91957\\Desktop\\final_project\\process\\t...        2  \n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad65b57",
      "metadata": {
        "id": "fad65b57"
      },
      "outputs": [],
      "source": [
        "#image generatores\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "WARMUP_EPOCHS = 2\n",
        "LEARNING_RATE = 1e-4\n",
        "WARMUP_LEARNING_RATE = 1e-3\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "CANAL = 3\n",
        "#N_CLASSES = df['lan_code'].nunique()\n",
        "ES_PATIENCE = 5\n",
        "RLROP_PATIENCE = 3\n",
        "DECAY_DROP = 0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb17b718",
      "metadata": {
        "id": "fb17b718"
      },
      "outputs": [],
      "source": [
        "#image generatores\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 5\n",
        "WARMUP_EPOCHS = 2\n",
        "LEARNING_RATE = 1e-4\n",
        "WARMUP_LEARNING_RATE = 1e-3\n",
        "HEIGHT = 224\n",
        "WIDTH = 224\n",
        "CANAL = 3\n",
        "N_CLASSES = df['lan_code'].nunique()\n",
        "ES_PATIENCE = 5\n",
        "RLROP_PATIENCE = 3\n",
        "DECAY_DROP = 0.5\n",
        "def img_generator(train,test):\n",
        "    train_datagen=ImageDataGenerator(rescale=1./255, validation_split=0.2,horizontal_flip=True)\n",
        "\n",
        "    train_generator=train_datagen.flow_from_dataframe(dataframe=train,\n",
        "\n",
        "                                                      x_col=\"file_path\",\n",
        "                                                      y_col=\"lan_code\",\n",
        "                                                      batch_size=BATCH_SIZE,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(HEIGHT, WIDTH),\n",
        "                                                      subset='training')\n",
        "\n",
        "    valid_generator=train_datagen.flow_from_dataframe(dataframe=train,\n",
        "\n",
        "                                                      x_col=\"file_path\",\n",
        "                                                      y_col=\"lan_code\",\n",
        "                                                      batch_size=BATCH_SIZE,\n",
        "                                                      class_mode=\"categorical\",\n",
        "                                                      target_size=(HEIGHT, WIDTH),\n",
        "                                                      subset='validation')\n",
        "\n",
        "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    test_generator = test_datagen.flow_from_dataframe(dataframe=test,\n",
        "\n",
        "                                                      x_col=\"file_path\",\n",
        "                                                      target_size=(HEIGHT, WIDTH),\n",
        "                                                      batch_size=1,\n",
        "                                                      shuffle=False,\n",
        "                                                      class_mode=None)\n",
        "\n",
        "    return train_generator,valid_generator,test_generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527982eb",
      "metadata": {
        "id": "527982eb",
        "outputId": "b3ae36a6-c48d-4c5b-974a-7d17fcdab3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 480 validated image filenames belonging to 3 classes.\n",
            "Found 120 validated image filenames belonging to 3 classes.\n",
            "Found 150 validated image filenames.\n"
          ]
        }
      ],
      "source": [
        "train_generator,valid_generator,test_generator = img_generator(train,test)#calling image_generator function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ced103",
      "metadata": {
        "scrolled": true,
        "id": "20ced103",
        "outputId": "8a46b0a2-dc1a-49bf-ddc7-59c5e0009485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 286, 430, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 286, 430, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 284, 428, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 284, 428, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 142, 214, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 142, 214, 64)      0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 140, 212, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 140, 212, 128)    512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 140, 212, 128)     0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 138, 210, 256)     295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 138, 210, 256)    1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 69, 105, 256)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 69, 105, 256)      0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 67, 103, 512)      1180160   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 67, 103, 512)     2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 33, 51, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 33, 51, 512)       0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 861696)            0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 861696)           3446784   \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 256)               220594432 \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,615,555\n",
            "Trainable params: 223,889,667\n",
            "Non-trainable params: 1,725,888\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#CNN model\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "cnn4 = Sequential()\n",
        "cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,3)))\n",
        "cnn4.add(BatchNormalization())\n",
        "\n",
        "cnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn4.add(Dropout(0.25))\n",
        "\n",
        "cnn4.add(Flatten())\n",
        "\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dense(256, activation='relu'))\n",
        "cnn4.add(BatchNormalization())\n",
        "cnn4.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "cnn4.add(Dense(3, activation='softmax'))\n",
        "\n",
        "cnn4.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "cnn4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25e1ebaf",
      "metadata": {
        "id": "25e1ebaf"
      },
      "outputs": [],
      "source": [
        " earlystop = tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                min_delta=0,\n",
        "                patience=20,\n",
        "                verbose=1,\n",
        "                mode='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0daf263c",
      "metadata": {
        "id": "0daf263c"
      },
      "outputs": [],
      "source": [
        "modelCheckPoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "                    filepath=\"./checkPointModel.h5\",\n",
        "                    save_best_only=True,\n",
        "                    monitor='val_loss',\n",
        "                    mode='auto',\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69351d7f",
      "metadata": {
        "id": "69351d7f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "NAME = \"recurrent_model\"\n",
        "tensorboard = TensorBoard(log_dir='./logs/recurrent_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6510823",
      "metadata": {
        "scrolled": true,
        "id": "c6510823",
        "outputId": "86a26c1a-f30c-42d4-e640-dc4a71fd3092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 1.5365 - accuracy: 0.5938\n",
            "Epoch 00001: val_loss improved from inf to 7.84508, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 503s 8s/step - loss: 1.5365 - accuracy: 0.5938 - val_loss: 7.8451 - val_accuracy: 0.3167\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.7307 - accuracy: 0.7583\n",
            "Epoch 00002: val_loss improved from 7.84508 to 2.70114, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 536s 9s/step - loss: 0.7307 - accuracy: 0.7583 - val_loss: 2.7011 - val_accuracy: 0.3167\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.7937\n",
            "Epoch 00003: val_loss did not improve from 2.70114\n",
            "60/60 [==============================] - 362s 6s/step - loss: 0.5884 - accuracy: 0.7937 - val_loss: 3.7173 - val_accuracy: 0.3167\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4027 - accuracy: 0.8458\n",
            "Epoch 00004: val_loss improved from 2.70114 to 1.17248, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 364s 6s/step - loss: 0.4027 - accuracy: 0.8458 - val_loss: 1.1725 - val_accuracy: 0.5583\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.8458\n",
            "Epoch 00005: val_loss did not improve from 1.17248\n",
            "60/60 [==============================] - 350s 6s/step - loss: 0.4029 - accuracy: 0.8458 - val_loss: 2.0227 - val_accuracy: 0.5583\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8625\n",
            "Epoch 00006: val_loss did not improve from 1.17248\n",
            "60/60 [==============================] - 331s 6s/step - loss: 0.3660 - accuracy: 0.8625 - val_loss: 1.1846 - val_accuracy: 0.5750\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3144 - accuracy: 0.8729\n",
            "Epoch 00007: val_loss improved from 1.17248 to 1.04424, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 336s 6s/step - loss: 0.3144 - accuracy: 0.8729 - val_loss: 1.0442 - val_accuracy: 0.5750\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.8667\n",
            "Epoch 00008: val_loss improved from 1.04424 to 0.20009, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 341s 6s/step - loss: 0.3717 - accuracy: 0.8667 - val_loss: 0.2001 - val_accuracy: 0.9417\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.8979\n",
            "Epoch 00009: val_loss improved from 0.20009 to 0.15998, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 343s 6s/step - loss: 0.2372 - accuracy: 0.8979 - val_loss: 0.1600 - val_accuracy: 0.9417\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9250\n",
            "Epoch 00010: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 336s 6s/step - loss: 0.2037 - accuracy: 0.9250 - val_loss: 0.6519 - val_accuracy: 0.7833\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.9146 \n",
            "Epoch 00011: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 2067s 35s/step - loss: 0.2223 - accuracy: 0.9146 - val_loss: 1.8854 - val_accuracy: 0.5083\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9104\n",
            "Epoch 00012: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 549s 9s/step - loss: 0.2395 - accuracy: 0.9104 - val_loss: 0.1671 - val_accuracy: 0.9417\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9187\n",
            "Epoch 00013: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 530s 9s/step - loss: 0.2071 - accuracy: 0.9187 - val_loss: 1.3964 - val_accuracy: 0.6667\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9438\n",
            "Epoch 00014: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 544s 9s/step - loss: 0.1875 - accuracy: 0.9438 - val_loss: 0.3715 - val_accuracy: 0.8667\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9354\n",
            "Epoch 00015: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 485s 8s/step - loss: 0.1608 - accuracy: 0.9354 - val_loss: 0.3529 - val_accuracy: 0.9083\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9250\n",
            "Epoch 00016: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 377s 6s/step - loss: 0.1778 - accuracy: 0.9250 - val_loss: 0.2872 - val_accuracy: 0.9250\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.9250\n",
            "Epoch 00017: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 378s 6s/step - loss: 0.1989 - accuracy: 0.9250 - val_loss: 0.2143 - val_accuracy: 0.9417\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9250\n",
            "Epoch 00018: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 380s 6s/step - loss: 0.1867 - accuracy: 0.9250 - val_loss: 0.9895 - val_accuracy: 0.7000\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9563\n",
            "Epoch 00019: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 374s 6s/step - loss: 0.1274 - accuracy: 0.9563 - val_loss: 1.7775 - val_accuracy: 0.5500\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9646\n",
            "Epoch 00020: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 371s 6s/step - loss: 0.0992 - accuracy: 0.9646 - val_loss: 0.2064 - val_accuracy: 0.9250\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.9583\n",
            "Epoch 00021: val_loss did not improve from 0.15998\n",
            "60/60 [==============================] - 374s 6s/step - loss: 0.1293 - accuracy: 0.9583 - val_loss: 0.7106 - val_accuracy: 0.7667\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9479\n",
            "Epoch 00022: val_loss improved from 0.15998 to 0.14783, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 374s 6s/step - loss: 0.1244 - accuracy: 0.9479 - val_loss: 0.1478 - val_accuracy: 0.9333\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1268 - accuracy: 0.9479\n",
            "Epoch 00023: val_loss did not improve from 0.14783\n",
            "60/60 [==============================] - 370s 6s/step - loss: 0.1268 - accuracy: 0.9479 - val_loss: 1.4319 - val_accuracy: 0.6333\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.9521\n",
            "Epoch 00024: val_loss did not improve from 0.14783\n",
            "60/60 [==============================] - 379s 6s/step - loss: 0.1138 - accuracy: 0.9521 - val_loss: 0.4620 - val_accuracy: 0.8417\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.9542\n",
            "Epoch 00025: val_loss did not improve from 0.14783\n",
            "60/60 [==============================] - 380s 6s/step - loss: 0.1343 - accuracy: 0.9542 - val_loss: 0.6242 - val_accuracy: 0.8167\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1173 - accuracy: 0.9604\n",
            "Epoch 00026: val_loss did not improve from 0.14783\n",
            "60/60 [==============================] - 376s 6s/step - loss: 0.1173 - accuracy: 0.9604 - val_loss: 0.2100 - val_accuracy: 0.9417\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0847 - accuracy: 0.9646\n",
            "Epoch 00027: val_loss improved from 0.14783 to 0.08066, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 369s 6s/step - loss: 0.0847 - accuracy: 0.9646 - val_loss: 0.0807 - val_accuracy: 0.9750\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.9396\n",
            "Epoch 00028: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 360s 6s/step - loss: 0.1358 - accuracy: 0.9396 - val_loss: 0.4949 - val_accuracy: 0.8167\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9750\n",
            "Epoch 00029: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 369s 6s/step - loss: 0.0756 - accuracy: 0.9750 - val_loss: 0.4434 - val_accuracy: 0.8583\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9646\n",
            "Epoch 00030: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 364s 6s/step - loss: 0.0888 - accuracy: 0.9646 - val_loss: 0.1406 - val_accuracy: 0.9583\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.9583\n",
            "Epoch 00031: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 366s 6s/step - loss: 0.0975 - accuracy: 0.9583 - val_loss: 0.1171 - val_accuracy: 0.9583\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.9604\n",
            "Epoch 00032: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 366s 6s/step - loss: 0.0999 - accuracy: 0.9604 - val_loss: 5.3411 - val_accuracy: 0.3000\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.9563\n",
            "Epoch 00033: val_loss did not improve from 0.08066\n",
            "60/60 [==============================] - 367s 6s/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.2720 - val_accuracy: 0.8917\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9750\n",
            "Epoch 00034: val_loss improved from 0.08066 to 0.06356, saving model to .\\checkPointModel.h5\n",
            "60/60 [==============================] - 369s 6s/step - loss: 0.0711 - accuracy: 0.9750 - val_loss: 0.0636 - val_accuracy: 0.9833\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.9750\n",
            "Epoch 00035: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 368s 6s/step - loss: 0.0867 - accuracy: 0.9750 - val_loss: 0.2092 - val_accuracy: 0.9083\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.9833\n",
            "Epoch 00036: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 363s 6s/step - loss: 0.0494 - accuracy: 0.9833 - val_loss: 0.0927 - val_accuracy: 0.9667\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9521\n",
            "Epoch 00037: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 332s 6s/step - loss: 0.1351 - accuracy: 0.9521 - val_loss: 1.4369 - val_accuracy: 0.6083\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9563\n",
            "Epoch 00038: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 333s 6s/step - loss: 0.1063 - accuracy: 0.9563 - val_loss: 0.5057 - val_accuracy: 0.8250\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.9750\n",
            "Epoch 00039: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 333s 6s/step - loss: 0.0766 - accuracy: 0.9750 - val_loss: 0.8253 - val_accuracy: 0.7917\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9583\n",
            "Epoch 00040: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 333s 6s/step - loss: 0.1281 - accuracy: 0.9583 - val_loss: 1.5917 - val_accuracy: 0.6667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f42debd7c0>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#CNN model training\n",
        "cnn4.fit(train_generator, batch_size = BATCH_SIZE, epochs = 40, verbose = 1, validation_data = valid_generator,callbacks = [tensorboard , earlystop ,modelCheckPoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab27f37",
      "metadata": {
        "id": "6ab27f37",
        "outputId": "32e6edae-2116-497a-ebfc-f16b66f4f12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 31s 203ms/step\n"
          ]
        }
      ],
      "source": [
        "#predicting test data using CNN\n",
        "train_preds =cnn4.predict_generator(test_generator, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba6f7591",
      "metadata": {
        "id": "ba6f7591",
        "outputId": "1a30c8ad-98a9-479b-f304-b1286bf16486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN Accuracy score : 0.653\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#printing accuracy and confusion matrix of CNN\n",
        "y_pred=np.argmax(train_preds,axis=1)\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score\n",
        "p=confusion_matrix(test['lan_code'].astype(\"int\"),y_pred)\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16, 7))\n",
        "sns.heatmap(p,annot=True)\n",
        "y_pred=np.argmax(train_preds,axis=1)\n",
        "print(\"CNN Accuracy score : %.3f\" % accuracy_score(test['lan_code'].astype('int'),y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93004d6",
      "metadata": {
        "id": "f93004d6"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "from prettytable import PrettyTable\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import keras\n",
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img\n",
        "from keras import optimizers,Model,Sequential\n",
        "from keras.layers import Input,GlobalAveragePooling2D,Dropout,Dense,Activation,Flatten\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import pandas as pd\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import concatenate\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "import tensorflow as kf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e77c2f3",
      "metadata": {
        "id": "3e77c2f3"
      },
      "outputs": [],
      "source": [
        "#ResNet50\n",
        "import tensorflow as tf\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(224,224,3),\n",
        "                   pooling='max',classes=3,\n",
        "                   weights='imagenet')\n",
        "\n",
        "#pretrained_model.summary()\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(3, activation='softmax'))\n",
        "resnet_model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "#resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39b141b",
      "metadata": {
        "scrolled": true,
        "id": "d39b141b",
        "outputId": "55778f82-ce0c-47c1-e15d-73757045ce05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60/60 [==============================] - 245s 4s/step - loss: 9.8976 - accuracy: 0.5042 - val_loss: 1784.1447 - val_accuracy: 0.3167\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - 235s 4s/step - loss: 3.1910 - accuracy: 0.6500 - val_loss: 14.5807 - val_accuracy: 0.3000\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 1.8884 - accuracy: 0.6667 - val_loss: 1.0987 - val_accuracy: 0.3833\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.9861 - accuracy: 0.7542 - val_loss: 1.0960 - val_accuracy: 0.3833\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - 237s 4s/step - loss: 0.3994 - accuracy: 0.8687 - val_loss: 1.0957 - val_accuracy: 0.3833\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - 235s 4s/step - loss: 0.2918 - accuracy: 0.8958 - val_loss: 1.0964 - val_accuracy: 0.3833\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - 246s 4s/step - loss: 0.4446 - accuracy: 0.8896 - val_loss: 1.1052 - val_accuracy: 0.3833\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - 249s 4s/step - loss: 0.2276 - accuracy: 0.9271 - val_loss: 1.1052 - val_accuracy: 0.3833\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - 252s 4s/step - loss: 0.2675 - accuracy: 0.9229 - val_loss: 1.1376 - val_accuracy: 0.3167\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - 254s 4s/step - loss: 0.1804 - accuracy: 0.9396 - val_loss: 1.1382 - val_accuracy: 0.3833\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - 248s 4s/step - loss: 0.2026 - accuracy: 0.9396 - val_loss: 1.1369 - val_accuracy: 0.3833\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - 239s 4s/step - loss: 0.1801 - accuracy: 0.9396 - val_loss: 1.1589 - val_accuracy: 0.3333\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0731 - accuracy: 0.9729 - val_loss: 1.3236 - val_accuracy: 0.4250\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - 236s 4s/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.7894 - val_accuracy: 0.6667\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.2877 - accuracy: 0.9021 - val_loss: 0.9446 - val_accuracy: 0.7333\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.2031 - accuracy: 0.9479 - val_loss: 0.8013 - val_accuracy: 0.6833\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - 235s 4s/step - loss: 0.1879 - accuracy: 0.9354 - val_loss: 0.9022 - val_accuracy: 0.7250\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.1086 - accuracy: 0.9688 - val_loss: 0.1467 - val_accuracy: 0.9833\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.1866 - accuracy: 0.9458 - val_loss: 0.6378 - val_accuracy: 0.9250\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.1224 - accuracy: 0.9604 - val_loss: 0.1376 - val_accuracy: 0.9667\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0588 - accuracy: 0.9750 - val_loss: 0.1572 - val_accuracy: 0.9250\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.1009 - accuracy: 0.9729 - val_loss: 0.1950 - val_accuracy: 0.9667\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0519 - accuracy: 0.9854 - val_loss: 0.0733 - val_accuracy: 0.9833\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.0184 - accuracy: 0.9917 - val_loss: 0.3245 - val_accuracy: 0.9083\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0276 - accuracy: 0.9958 - val_loss: 0.2641 - val_accuracy: 0.9250\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - 235s 4s/step - loss: 0.0881 - accuracy: 0.9646 - val_loss: 0.1055 - val_accuracy: 0.9750\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - 236s 4s/step - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.0203 - val_accuracy: 0.9917\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0237 - accuracy: 0.9958 - val_loss: 0.0471 - val_accuracy: 0.9833\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.0300 - accuracy: 0.9917 - val_loss: 0.1962 - val_accuracy: 0.9417\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.1817 - accuracy: 0.9479 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - 233s 4s/step - loss: 0.0486 - accuracy: 0.9792 - val_loss: 0.2013 - val_accuracy: 0.9500\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - 237s 4s/step - loss: 0.0348 - accuracy: 0.9812 - val_loss: 0.2154 - val_accuracy: 0.9167\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - 234s 4s/step - loss: 0.0373 - accuracy: 0.9833 - val_loss: 0.3583 - val_accuracy: 0.9167\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - 238s 4s/step - loss: 0.1111 - accuracy: 0.9604 - val_loss: 0.1055 - val_accuracy: 0.9750\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - 241s 4s/step - loss: 0.0216 - accuracy: 0.9875 - val_loss: 0.1637 - val_accuracy: 0.9417\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - 243s 4s/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.1447 - val_accuracy: 0.9333\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - 236s 4s/step - loss: 0.0695 - accuracy: 0.9833 - val_loss: 0.5196 - val_accuracy: 0.9083\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - 237s 4s/step - loss: 0.1107 - accuracy: 0.9646 - val_loss: 0.7393 - val_accuracy: 0.8500\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - 240s 4s/step - loss: 0.0372 - accuracy: 0.9875 - val_loss: 0.1435 - val_accuracy: 0.9583\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - 247s 4s/step - loss: 0.0431 - accuracy: 0.9917 - val_loss: 0.0625 - val_accuracy: 0.9833\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f43f5df1f0>"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#training ResNet50 model\n",
        "resnet_model.fit(train_generator, batch_size = BATCH_SIZE, epochs = 40, verbose = 1, validation_data = valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390f2b82",
      "metadata": {
        "id": "390f2b82",
        "outputId": "ec0003b9-a8d3-41f6-8788-3f6e91547006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 26s 172ms/step\n",
            "ResNet50 Accuracy score : 0.967\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_preds1 =resnet_model.predict_generator(test_generator, verbose = 1)#predicting test data using ResNet50\n",
        "y_pred1=np.argmax(train_preds1,axis=1)\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score\n",
        "p=confusion_matrix(test['lan_code'].astype(\"int\"),y_pred1)\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16, 7))\n",
        "sns.heatmap(p,annot=True)#ploting confusion matrix\n",
        "print(\"ResNet50 Accuracy score : %.3f\" % accuracy_score(test['lan_code'].astype('int'),y_pred1))#finding accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c42f2e",
      "metadata": {
        "id": "52c42f2e"
      },
      "outputs": [],
      "source": [
        "#inceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "import tensorflow as tf\n",
        "base_model = InceptionV3(weights='imagenet',\n",
        "                                include_top=False,\n",
        "                                input_shape=(224, 224,3))\n",
        "base_model.trainable = False\n",
        "\n",
        "add_model = Sequential()\n",
        "add_model.add(base_model)\n",
        "add_model.add(Flatten())\n",
        "add_model.add(Dense(1024,\n",
        "                    activation='relu'))\n",
        "add_model.add(Dropout(0.2))\n",
        "add_model.add(Dense(3,\n",
        "                    activation='softmax'))\n",
        "\n",
        "model = add_model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42c5e709",
      "metadata": {
        "scrolled": true,
        "id": "42c5e709",
        "outputId": "90f83b4f-0d0a-4578-c68c-17cee326a088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 46.0924 - accuracy: 0.4479\n",
            "Epoch 00001: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 68s 1s/step - loss: 46.0924 - accuracy: 0.4479 - val_loss: 22.1650 - val_accuracy: 0.6083\n",
            "Epoch 2/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 11.6893 - accuracy: 0.6208\n",
            "Epoch 00002: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 11.6893 - accuracy: 0.6208 - val_loss: 6.3693 - val_accuracy: 0.6833\n",
            "Epoch 3/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 3.5085 - accuracy: 0.7500\n",
            "Epoch 00003: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 3.5085 - accuracy: 0.7500 - val_loss: 3.2350 - val_accuracy: 0.6333\n",
            "Epoch 4/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 1.5376 - accuracy: 0.8083\n",
            "Epoch 00004: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 1.5376 - accuracy: 0.8083 - val_loss: 2.0699 - val_accuracy: 0.7083\n",
            "Epoch 5/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.7464 - accuracy: 0.8458\n",
            "Epoch 00005: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.7464 - accuracy: 0.8458 - val_loss: 1.2015 - val_accuracy: 0.7667\n",
            "Epoch 6/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.7666 - accuracy: 0.8333\n",
            "Epoch 00006: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.7666 - accuracy: 0.8333 - val_loss: 0.5788 - val_accuracy: 0.7917\n",
            "Epoch 7/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.9000\n",
            "Epoch 00007: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.3321 - accuracy: 0.9000 - val_loss: 0.5498 - val_accuracy: 0.8500\n",
            "Epoch 8/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2615 - accuracy: 0.9062\n",
            "Epoch 00008: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.2615 - accuracy: 0.9062 - val_loss: 0.6162 - val_accuracy: 0.8167\n",
            "Epoch 9/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.9229\n",
            "Epoch 00009: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.2261 - accuracy: 0.9229 - val_loss: 0.6107 - val_accuracy: 0.8250\n",
            "Epoch 10/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.8979\n",
            "Epoch 00010: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 63s 1s/step - loss: 0.4888 - accuracy: 0.8979 - val_loss: 0.3982 - val_accuracy: 0.8750\n",
            "Epoch 11/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9375\n",
            "Epoch 00011: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 64s 1s/step - loss: 0.1748 - accuracy: 0.9375 - val_loss: 0.9243 - val_accuracy: 0.7750\n",
            "Epoch 12/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3190 - accuracy: 0.8938\n",
            "Epoch 00012: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 64s 1s/step - loss: 0.3190 - accuracy: 0.8938 - val_loss: 0.4025 - val_accuracy: 0.8500\n",
            "Epoch 13/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9458\n",
            "Epoch 00013: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.1992 - accuracy: 0.9458 - val_loss: 0.7616 - val_accuracy: 0.8000\n",
            "Epoch 14/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.9104\n",
            "Epoch 00014: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.2491 - accuracy: 0.9104 - val_loss: 0.7229 - val_accuracy: 0.7833\n",
            "Epoch 15/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.9563\n",
            "Epoch 00015: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 68s 1s/step - loss: 0.1101 - accuracy: 0.9563 - val_loss: 0.3635 - val_accuracy: 0.8750\n",
            "Epoch 16/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 0.9625\n",
            "Epoch 00016: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1009 - accuracy: 0.9625 - val_loss: 0.7069 - val_accuracy: 0.8000\n",
            "Epoch 17/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9833\n",
            "Epoch 00017: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.0495 - accuracy: 0.9833 - val_loss: 0.6244 - val_accuracy: 0.8167\n",
            "Epoch 18/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9812\n",
            "Epoch 00018: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.0652 - accuracy: 0.9812 - val_loss: 0.3429 - val_accuracy: 0.9000\n",
            "Epoch 19/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9750\n",
            "Epoch 00019: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.0667 - accuracy: 0.9750 - val_loss: 0.5240 - val_accuracy: 0.8500\n",
            "Epoch 20/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9708\n",
            "Epoch 00020: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 64s 1s/step - loss: 0.0923 - accuracy: 0.9708 - val_loss: 0.6184 - val_accuracy: 0.8750\n",
            "Epoch 21/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9729\n",
            "Epoch 00021: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 64s 1s/step - loss: 0.0736 - accuracy: 0.9729 - val_loss: 0.4427 - val_accuracy: 0.8750\n",
            "Epoch 22/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9917\n",
            "Epoch 00022: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 0.3595 - val_accuracy: 0.8917\n",
            "Epoch 23/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9833\n",
            "Epoch 00023: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.4138 - val_accuracy: 0.8833\n",
            "Epoch 24/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.9729\n",
            "Epoch 00024: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.1014 - accuracy: 0.9729 - val_loss: 0.4119 - val_accuracy: 0.8500\n",
            "Epoch 25/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.9021\n",
            "Epoch 00025: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 73s 1s/step - loss: 0.3651 - accuracy: 0.9021 - val_loss: 0.8485 - val_accuracy: 0.7583\n",
            "Epoch 26/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.9208\n",
            "Epoch 00026: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 68s 1s/step - loss: 0.2333 - accuracy: 0.9208 - val_loss: 0.8285 - val_accuracy: 0.7917\n",
            "Epoch 27/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.3045 - accuracy: 0.9000\n",
            "Epoch 00027: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.3045 - accuracy: 0.9000 - val_loss: 0.4741 - val_accuracy: 0.8250\n",
            "Epoch 28/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9500\n",
            "Epoch 00028: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 64s 1s/step - loss: 0.1608 - accuracy: 0.9500 - val_loss: 0.8989 - val_accuracy: 0.7750\n",
            "Epoch 29/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9396\n",
            "Epoch 00029: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.1781 - accuracy: 0.9396 - val_loss: 0.3329 - val_accuracy: 0.8833\n",
            "Epoch 30/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1300 - accuracy: 0.9604\n",
            "Epoch 00030: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.1300 - accuracy: 0.9604 - val_loss: 0.6524 - val_accuracy: 0.7667\n",
            "Epoch 31/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.9688\n",
            "Epoch 00031: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.0987 - accuracy: 0.9688 - val_loss: 0.4452 - val_accuracy: 0.8750\n",
            "Epoch 32/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9500\n",
            "Epoch 00032: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.1488 - accuracy: 0.9500 - val_loss: 0.8480 - val_accuracy: 0.8000\n",
            "Epoch 33/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9250\n",
            "Epoch 00033: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.2141 - accuracy: 0.9250 - val_loss: 0.6882 - val_accuracy: 0.8000\n",
            "Epoch 34/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9208\n",
            "Epoch 00034: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 69s 1s/step - loss: 0.1730 - accuracy: 0.9208 - val_loss: 0.5407 - val_accuracy: 0.7917\n",
            "Epoch 35/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9500\n",
            "Epoch 00035: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 65s 1s/step - loss: 0.1482 - accuracy: 0.9500 - val_loss: 0.6642 - val_accuracy: 0.8833\n",
            "Epoch 36/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.9417\n",
            "Epoch 00036: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 66s 1s/step - loss: 0.1775 - accuracy: 0.9417 - val_loss: 0.3391 - val_accuracy: 0.8333\n",
            "Epoch 37/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.9521\n",
            "Epoch 00037: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.1221 - accuracy: 0.9521 - val_loss: 0.6723 - val_accuracy: 0.7583\n",
            "Epoch 38/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9479\n",
            "Epoch 00038: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 68s 1s/step - loss: 0.1308 - accuracy: 0.9479 - val_loss: 0.5419 - val_accuracy: 0.8167\n",
            "Epoch 39/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.9479\n",
            "Epoch 00039: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 68s 1s/step - loss: 0.1465 - accuracy: 0.9479 - val_loss: 0.3564 - val_accuracy: 0.8917\n",
            "Epoch 40/40\n",
            "60/60 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.9708\n",
            "Epoch 00040: val_loss did not improve from 0.06356\n",
            "60/60 [==============================] - 67s 1s/step - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.3730 - val_accuracy: 0.9000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f443a1e070>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#training InceptionV3\n",
        "model.fit(train_generator, batch_size = BATCH_SIZE, epochs = 40, verbose = 1, validation_data = valid_generator,callbacks = [tensorboard , earlystop ,modelCheckPoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fffc045e",
      "metadata": {
        "id": "fffc045e",
        "outputId": "0e7a48b7-7632-4c49-8c18-a4752b631776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "150/150 [==============================] - 21s 141ms/step\n",
            "InceptionV3 Accuracy score : 0.847\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_preds2 =model.predict_generator(test_generator, verbose = 1)#predicting test data using InceptionV3\n",
        "y_pred2=np.argmax(train_preds2,axis=1)\n",
        "from sklearn.metrics import confusion_matrix, cohen_kappa_score,accuracy_score\n",
        "p=confusion_matrix(test['lan_code'].astype(\"int\"),y_pred2)\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(16, 7))\n",
        "sns.heatmap(p,annot=True)#ploting confusion matrix\n",
        "print(\"InceptionV3 Accuracy score : %.3f\" % accuracy_score(test['lan_code'].astype('int'),y_pred2))#accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "183fb579",
      "metadata": {
        "id": "183fb579"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}